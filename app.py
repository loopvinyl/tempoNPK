import streamlit as st
import pandas as pd
import numpy as np
from scipy.stats import kruskal
import matplotlib.pyplot as plt
import seaborn as sns
import tabula
import base64
import io
import re # Importa o m√≥dulo de express√µes regulares

# Configura√ß√µes gerais
st.set_page_config(page_title="An√°lise Estat√≠stica de Vermicompostagem", layout="wide")
st.title("üìä An√°lise Estat√≠stica de Par√¢metros de Vermicomposto")
st.markdown("""
**Aplica√ß√£o para an√°lise de diferen√ßas significativas em par√¢metros de vermicomposto ao longo do tempo**
Utiliza o teste de Kruskal-Wallis (n√£o param√©trico) para pequenas amostras.
""")

## Fun√ß√£o para Carregar Dados de Exemplo (Simulando R√©plicas com M√©dia e DP)
def load_sample_data_with_stdev():
    """
    Dados de exemplo baseados no artigo DERMENDZHIEVA et al. (2021).
    Simula um n√∫mero fixo de r√©plicas por dia para cada par√¢metro,
    utilizando valores de m√©dia e desvio padr√£o para gerar os dados.
    Estes valores s√£o **ilustrativos** e devem ser substitu√≠dos por dados reais do artigo
    quando a extra√ß√£o do PDF for bem-sucedida.
    """
    # Exemplo de m√©dias e desvios padr√£o (valores ilustrativos para demonstrar variabilidade)
    # Estes valores foram ajustados para que o teste de Kruskal-Wallis tenha uma boa chance de
    # encontrar signific√¢ncia para TKN, Total P e C/N, e n√£o para pH e TK (para mostrar ambos os casos).
    sample_param_data = {
        'TKN (gkg‚Åª¬π)': {
            'Day 1': {'mean': 20.8, 'stdev': 0.5},
            'Day 30': {'mean': 21.5, 'stdev': 0.6},
            'Day 60': {'mean': 22.2, 'stdev': 0.7},
            'Day 90': {'mean': 23.0, 'stdev': 0.8},
            'Day 120': {'mean': 24.5, 'stdev': 0.9}
        },
        'Total P (gkg‚Åª¬π)': {
            'Day 1': {'mean': 12.1, 'stdev': 0.3},
            'Day 30': {'mean': 12.8, 'stdev': 0.4},
            'Day 60': {'mean': 13.5, 'stdev': 0.4},
            'Day 90': {'mean': 14.2, 'stdev': 0.5},
            'Day 120': {'mean': 15.0, 'stdev': 0.6}
        },
        'TK (gkg‚Åª¬π)': { # Este ter√° pouca varia√ß√£o para mostrar "sem diferen√ßas significativas"
            'Day 1': {'mean': 1.28, 'stdev': 0.02},
            'Day 30': {'mean': 1.29, 'stdev': 0.02},
            'Day 60': {'mean': 1.30, 'stdev': 0.02},
            'Day 90': {'mean': 1.31, 'stdev': 0.02},
            'Day 120': {'mean': 1.32, 'stdev': 0.02}
        },
        'pH (H‚ÇÇO)': { # Este ter√° pouca varia√ß√£o para mostrar "sem diferen√ßas significativas"
            'Day 1': {'mean': 7.04, 'stdev': 0.05},
            'Day 30': {'mean': 7.00, 'stdev': 0.05},
            'Day 60': {'mean': 6.95, 'stdev': 0.05},
            'Day 90': {'mean': 6.90, 'stdev': 0.05},
            'Day 120': {'mean': 6.85, 'stdev': 0.05}
        },
        'C/N ratio': {
            'Day 1': {'mean': 11.2, 'stdev': 0.2},
            'Day 30': {'mean': 10.9, 'stdev': 0.25},
            'Day 60': {'mean': 10.5, 'stdev': 0.3},
            'Day 90': {'mean': 10.0, 'stdev': 0.35},
            'Day 120': {'mean': 9.5, 'stdev': 0.4}
        }
    }

    num_replications = 3 # N√∫mero de r√©plicas por ponto de dados, conforme o artigo
    days = ['Day 1', 'Day 30', 'Day 60', 'Day 90', 'Day 120']
    all_replicated_data = []

    for param_name, daily_stats in sample_param_data.items():
        for i in range(num_replications): # Gera 'num_replications' linhas para cada par√¢metro
            row_data = {'Parameter': param_name, 'Substrate': 'VC-M'}
            for day in days:
                stats = daily_stats.get(day)
                if stats:
                    # Gera um valor aleat√≥rio com base na m√©dia e desvio padr√£o
                    # Usamos `np.random.normal` para simular uma distribui√ß√£o normal.
                    simulated_value = np.random.normal(loc=stats['mean'], scale=stats['stdev'], size=1)[0]
                    
                    # Garante que valores simulados para pH n√£o saiam do intervalo [0, 14]
                    if param_name == 'pH (H‚ÇÇO)':
                        simulated_value = max(0.0, min(14.0, simulated_value))
                    # Garante que outros valores (como concentra√ß√µes, ratios) n√£o sejam negativos
                    elif 'gkg‚Åª¬π' in param_name or 'ratio' in param_name:
                        simulated_value = max(0.0, simulated_value)
                    
                    row_data[day] = simulated_value
                else:
                    row_data[day] = np.nan # Se n√£o houver dados para o dia
            all_replicated_data.append(row_data)

    return pd.DataFrame(all_replicated_data)

## Fun√ß√£o Principal
def main():
    # Op√ß√µes de Dados na Sidebar
    st.sidebar.header("Op√ß√µes de Dados")
    use_sample = st.sidebar.checkbox("Usar dados de exemplo", value=True)

    df = pd.DataFrame() # Inicializa df para garantir que sempre haja um DataFrame

    if use_sample:
        df = load_sample_data_with_stdev()
        st.sidebar.success("Usando dados de exemplo (r√©plicas simuladas com m√©dia e DP).")
    else:
        uploaded_file = st.sidebar.file_uploader("Carregue o artigo PDF", type="pdf")
        if not uploaded_file:
            st.info("Por favor, carregue um PDF ou marque 'Usar dados de exemplo'.")
            return

        st.sidebar.info(f"Arquivo carregado: {uploaded_file.name}")
        try:
            # --- In√≠cio da Extra√ß√£o Espec√≠fica para o PDF Anexado (DERMENDZHIEVA et al. (2021)) ---
            # A Tabela 2 est√° na p√°gina 4. Os par√¢metros s√£o as linhas e os dias s√£o as colunas (Mean ¬± SD).
            # Vamos tentar extrair a √°rea da tabela 2 para VC-M e VC-P.
            
            st.sidebar.info("Tentando extrair a Tabela 2 (p√°gina 4) do PDF.")
            
            # Coordenadas da √°rea da Tabela 2 (para ambos VC-M e VC-P).
            # Ajuste estas coordenadas [top, left, bottom, right] conforme necess√°rio.
            # Usei valores aproximados com base na visualiza√ß√£o do PDF.
            area_table2 = [385, 90, 680, 810] 
            
            # Colunas aproximadas para 'Parameter', e os dias (0, 30, 60, 90, 120)
            # O tabula tentar√° dividir com base nestes pontos de corte.
            # A tabela tem colunas como 'Parameter', 'Initial', 'Day 30', etc., e sub-colunas para 'Mean' e 'SD'.
            # tabula.read_pdf pode juntar Mean e SD na mesma c√©lula ou separ√°-los em colunas diferentes.
            # O p√≥s-processamento ser√° crucial.
            columns_table2 = [190, 260, 320, 380, 440, 500, 560, 620, 680, 740] # Ajustar essas colunas para pegar Mean e SD

            tables = tabula.read_pdf(
                io.BytesIO(uploaded_file.getvalue()), # Passa o conte√∫do do arquivo como bytes
                pages=4,
                multiple_tables=False,
                area=area_table2,
                columns=columns_table2,
                output_format='dataframe',
                lattice=True, # Usar lattice=True para tabelas com linhas de grade (que √© o caso da Tabela 2)
                pandas_options={'header': None} # tabula nem sempre infere o cabe√ßalho corretamente
            )
            
            if tables:
                df_raw = tables[0]
                st.sidebar.write("DataFrame cru extra√≠do (Tabela 2, P√°g 4):")
                st.sidebar.dataframe(df_raw)

                # --- P√≥s-processamento do DataFrame extra√≠do ---
                # A Tabela 2 do artigo tem uma estrutura de cabe√ßalho multin√≠vel e dados "Mean ¬± SD".
                # O tabula pode extrair de forma complexa. Vamos focar em pegar os valores Mean e SD.

                # A primeira coluna geralmente √© o par√¢metro.
                # As colunas 1, 3, 5, 7, 9 cont√™m os valores para 'Initial' (Day 0), 'Day 30', 'Day 60', 'Day 90', 'Day 120'.
                # As colunas 2, 4, 6, 8, 10 conteriam os SDs, mas muitas vezes tabula agrupa "Mean ¬± SD"
                
                # Nomes dos par√¢metros como aparecem no PDF
                pdf_param_names = {
                    'TKN (g kg-1)': 'TKN (gkg‚Åª¬π)',
                    'Total P (g kg-1)': 'Total P (gkg‚Åª¬π)',
                    'TK (g kg-1)': 'TK (gkg‚Åª¬π)',
                    'pH (H2O)': 'pH (H‚ÇÇO)',
                    'C/N ratio': 'C/N ratio'
                }
                
                # Dias no artigo (Day 0 √© Day 1 na nossa aplica√ß√£o)
                pdf_days = ['Initial', 'Day 30', 'Day 60', 'Day 90', 'Day 120']
                
                # Lista para armazenar os dados de m√©dia e desvio padr√£o para simula√ß√£o
                extracted_data_for_simulation = {}

                # Iterar sobre as linhas do DataFrame extra√≠do para parsear
                # As linhas dos par√¢metros come√ßam tipicamente na linha 2 (√≠ndex 1) do DF bruto,
                # assumindo que a primeira linha pode ser parte do cabe√ßalho
                for idx, row in df_raw.iterrows():
                    param_raw_name = str(row.iloc[0]).strip() # Assume que o par√¢metro est√° na primeira coluna
                    
                    # Ignorar linhas que n√£o s√£o par√¢metros ou s√£o cabe√ßalhos residuais
                    if param_raw_name not in pdf_param_names and not any(p in param_raw_name for p in pdf_param_names):
                        continue
                    
                    # Tentar encontrar o nome padronizado do par√¢metro
                    standard_param_name = None
                    for pdf_name, std_name in pdf_param_names.items():
                        if pdf_name in param_raw_name:
                            standard_param_name = std_name
                            break
                    
                    if standard_param_name:
                        extracted_data_for_simulation[standard_param_name] = {}
                        col_offset = 1 # A partir da segunda coluna (√≠ndex 1) come√ßam os dados dos dias
                        
                        for i, day_name in enumerate(pdf_days):
                            cell_value = str(row.iloc[col_offset + i*2]).strip() # Assume Mean em colunas √≠mpares
                            
                            # Express√£o regular para extrair m√©dia e desvio padr√£o (ex: "20.8 ¬± 0.5")
                            match = re.match(r"(\d+\.?\d*)\s*¬±\s*(\d+\.?\d*)", cell_value)
                            if match:
                                mean_val = float(match.group(1))
                                stdev_val = float(match.group(2))
                                extracted_data_for_simulation[standard_param_name][day_name] = {
                                    'mean': mean_val,
                                    'stdev': stdev_val
                                }
                            else:
                                # Tenta extrair apenas o n√∫mero se n√£o encontrar '¬±'
                                try:
                                    mean_val = float(cell_value)
                                    # Se n√£o houver SD expl√≠cito, usamos um SD pequeno ou 0 para simular
                                    stdev_val = 0.01 * mean_val # Um pequeno percentual da m√©dia
                                    if stdev_val == 0: stdev_val = 0.01 # Evita SD zero
                                    extracted_data_for_simulation[standard_param_name][day_name] = {
                                        'mean': mean_val,
                                        'stdev': stdev_val
                                    }
                                except ValueError:
                                    # N√£o foi poss√≠vel extrair. Deixa como NaN ou lida com o erro.
                                    extracted_data_for_simulation[standard_param_name][day_name] = {'mean': np.nan, 'stdev': np.nan}
                
                # Agora, simular r√©plicas com base nos dados extra√≠dos do PDF
                num_replications_from_pdf = 3 # Assumindo 3 r√©plicas pelo estudo (ou valor que voc√™ especificar)
                replicated_pdf_data = []
                
                app_days_map = {
                    'Initial': 'Day 1', # Mapeia 'Initial' do PDF para 'Day 1' na aplica√ß√£o
                    'Day 30': 'Day 30',
                    'Day 60': 'Day 60',
                    'Day 90': 'Day 90',
                    'Day 120': 'Day 120'
                }

                for param_name, daily_stats in extracted_data_for_simulation.items():
                    for _ in range(num_replications_from_pdf):
                        row_data = {'Parameter': param_name, 'Substrate': 'VC-M'} # Assumindo VC-M para este exemplo
                        for pdf_day_name, app_day_name in app_days_map.items():
                            stats = daily_stats.get(pdf_day_name)
                            if stats and not np.isnan(stats['mean']) and not np.isnan(stats['stdev']):
                                simulated_value = np.random.normal(loc=stats['mean'], scale=stats['stdev'], size=1)[0]
                                
                                # Aplicar limites para valores simulados (pH, n√£o-negativos)
                                if param_name == 'pH (H‚ÇÇO)':
                                    simulated_value = max(0.0, min(14.0, simulated_value))
                                elif 'gkg‚Åª¬π' in param_name or 'ratio' in param_name:
                                    simulated_value = max(0.0, simulated_value)
                                    
                                row_data[app_day_name] = simulated_value
                            else:
                                row_data[app_day_name] = np.nan
                        replicated_pdf_data.append(row_data)

                df = pd.DataFrame(replicated_pdf_data)
                
                # Remove linhas que possam ter vindo vazias ou com apenas NaN nos dias
                df = df.dropna(subset=['Day 1', 'Day 30', 'Day 60', 'Day 90', 'Day 120'], how='all')

                if df.empty:
                    st.warning("Tabela extra√≠da, mas nenhum dado relevante foi encontrado ou simulado ap√≥s a limpeza. Usando dados de exemplo.")
                    df = load_sample_data_with_stdev()
                else:
                    st.sidebar.success("Tabela extra√≠da e r√©plicas simuladas com sucesso!")

            else:
                st.sidebar.warning("Nenhuma tabela encontrada na p√°gina 4 com os par√¢metros especificados. Usando dados de exemplo.")
                df = load_sample_data_with_stdev()
            # --- Fim da Extra√ß√£o Espec√≠fica para o PDF Anexado ---

        except Exception as e:
            st.sidebar.error(f"Erro na extra√ß√£o ou processamento do PDF: {str(e)}")
            st.error("N√£o foi poss√≠vel extrair ou processar a tabela. Usando dados de exemplo.")
            df = load_sample_data_with_stdev()

    ## Pr√©-visualiza√ß√£o dos Dados
    st.header("Pr√©-visualiza√ß√£o dos Dados")
    st.dataframe(df.head())
    st.markdown("---")

    ## Configura√ß√£o de An√°lise
    st.sidebar.header("Configura√ß√£o de An√°lise")
    
    unique_params_in_df = df['Parameter'].unique().tolist()
    
    # Mapeamento para exibi√ß√£o amig√°vel
    display_param_mapping = {
        "TKN (gkg‚Åª¬π)": "Nitrog√™nio Total (N)",
        "Total P (gkg‚Åª¬π)": "F√≥sforo Total (P)",
        "TK (gkg‚Åª¬π)": "Pot√°ssio Total (K)",
        "pH (H‚ÇÇO)": "pH",
        "C/N ratio": "Rela√ß√£o C/N"
    }
    
    # Criar uma lista para o multiselect que usa os nomes amig√°veis
    options_for_multiselect = [
        display_param_mapping.get(p_df, p_df) for p_df in unique_params_in_df
        if p_df in display_param_mapping or p_df # Inclui se est√° no mapeamento ou se n√£o tem mapeamento
    ]

    # Definir os padr√µes com base nas op√ß√µes dispon√≠veis
    default_selected_params = []
    for p_key in ["TKN (gkg‚Åª¬π)", "Total P (gkg‚Åª¬π)", "pH (H‚ÇÇO)", "C/N ratio"]: # Incluindo C/N como default
        if p_key in unique_params_in_df:
            default_selected_params.append(display_param_mapping.get(p_key, p_key))

    parameters = st.sidebar.multiselect(
        "Selecione os par√¢metros para an√°lise:",
        options=options_for_multiselect,
        default=default_selected_params
    )
    
    # Mapeamento reverso para obter o nome da coluna do DataFrame
    param_mapping_reverse = {v: k for k, v in display_param_mapping.items()}

    ## Realizar Testes Estat√≠sticos
    results = []
    
    # Determinar o n√∫mero de gr√°ficos para subplots
    num_plots = len(parameters)
    if num_plots > 0:
        # Ajusta o tamanho da figura dinamicamente
        fig, axes = plt.subplots(num_plots, 1, figsize=(10, 5 * num_plots))
        if num_plots == 1:
            axes = [axes] # Garante que axes seja sempre uma lista para itera√ß√£o

        for i, param_display_name in enumerate(parameters):
            col_name_in_df = param_mapping_reverse.get(param_display_name, param_display_name) # Usar o nome real da coluna no DF
            param_df = df[df['Parameter'] == col_name_in_df]

            # Extrair dados para cada dia
            app_days_ordered = ['Day 1', 'Day 30', 'Day 60', 'Day 90', 'Day 120']
            
            # Coleta os dados de cada dia. Cada elemento em 'data' ser√° uma array de valores
            # para aquele dia (todas as r√©plicas simuladas para aquele par√¢metro naquele dia).
            data = []
            valid_days_for_plot = []
            for day in app_days_ordered:
                if day in param_df.columns:
                    day_values = param_df[day].dropna().values
                    if len(day_values) > 0:
                        data.append(day_values)
                        valid_days_for_plot.append(day) # Apenas dias com dados para o gr√°fico
            
            # O teste de Kruskal-Wallis requer pelo menos 2 grupos com dados.
            if len(data) >= 2 and all(len(d) > 0 for d in data):
                h_stat, p_val = kruskal(*data)
                results.append({
                    "Par√¢metro": param_display_name,
                    "H-Statistic": h_stat,
                    "p-value": p_val,
                    "Significativo (p<0.05)": p_val < 0.05
                })

                # Criar gr√°fico
                ax = axes[i]
                for j, day_data in enumerate(data):
                    # Plotar cada ponto individualmente
                    ax.scatter([j] * len(day_data), day_data, alpha=0.6, label=f"{app_days_ordered[j].replace('Day ', 'Dia ')}")

                # Adicionar linha de tend√™ncia (medianas)
                medians = [np.median(day_data) for day_data in data]
                ax.plot(range(len(data)), medians, 'ro-', markersize=8)

                ax.set_title(f"Evolu√ß√£o do {param_display_name}")
                ax.set_ylabel(param_display_name.split('(')[0].strip())
                ax.set_xticks(range(len(data)))
                ax.set_xticklabels([d.replace('Day ', '') for d in valid_days_for_plot]) # R√≥tulos dos dias
                ax.grid(True, alpha=0.3)
                ax.legend()

                # Adicionar resultado do teste ao gr√°fico
                ax.annotate(f"Kruskal-Wallis: H = {h_stat:.2f}, p = {p_val:.4f}",
                            xy=(0.5, 0.05), xycoords='axes fraction',
                            ha='center', fontsize=9,
                            bbox=dict(boxstyle="round,pad=0.3", fc="yellow", alpha=0.3))
            else:
                st.warning(f"Dados insuficientes ou inconsistentes para o par√¢metro '{param_display_name}' para realizar a an√°lise de Kruskal-Wallis. Verifique a extra√ß√£o do PDF ou os dados de exemplo.")
    else:
        st.warning("Nenhum par√¢metro selecionado para an√°lise.")
        return

    st.header("Resultados Estat√≠sticos")
    results_df = pd.DataFrame(results)
    if not results_df.empty:
        st.dataframe(results_df.style.apply(
            lambda x: ['background-color: #fffd8e' if x['p-value'] < 0.05 else '' for _ in x],
            axis=1
        ))
    else:
        st.info("Nenhum resultado estat√≠stico para exibir. Verifique a sele√ß√£o de par√¢metros e os dados.")
    st.markdown("---")

    ## Evolu√ß√£o Temporal dos Par√¢metros
    st.header("Evolu√ß√£o Temporal dos Par√¢metros")
    # Tenta plotar apenas se houver uma figura criada e par√¢metros selecionados
    if 'fig' in locals() and fig is not None and num_plots > 0:
        st.pyplot(fig)
    else:
        st.info("Nenhum gr√°fico para exibir. Selecione par√¢metros para visualiz√°-los.")
    st.markdown("---")

    ## Interpreta√ß√£o dos Resultados
    st.header("Interpreta√ß√£o dos Resultados")
    if not results_df.empty:
        for res in results:
            st.subheader(res["Par√¢metro"])
            if res["p-value"] < 0.05:
                st.success(f"‚úÖ Diferen√ßas estatisticamente significativas (p = {res['p-value']:.4f})")
                st.markdown("""
                - **Rejeitamos a hip√≥tese nula (H‚ÇÄ)**.
                - H√° evid√™ncias de que os valores do par√¢metro **mudam significativamente** ao longo do tempo.
                - A vermicompostagem afeta este par√¢metro.
                """)
            else:
                st.warning(f"‚ùå Sem diferen√ßas significativas (p = {res['p-value']:.4f})")
                st.markdown("""
                - **Aceitamos a hip√≥tese nula (H‚ÇÄ)**.
                - N√£o h√° evid√™ncias suficientes de mudan√ßas significativas.
                - O par√¢metro permanece est√°vel durante o processo de vermicompostagem.
                """)
    else:
        st.info("Nenhuma interpreta√ß√£o dispon√≠vel, pois n√£o h√° resultados estat√≠sticos.")
    st.markdown("---")

    ## Sobre a Metodologia
    st.sidebar.header("Sobre a Metodologia")
    st.sidebar.info("""
    **Teste de Kruskal-Wallis:**
    - Teste n√£o param√©trico equivalente √† ANOVA de uma via.
    - Usado quando os dados n√£o atendem aos pressupostos de normalidade ou para pequenas amostras.
    - Compara as medianas de tr√™s ou mais grupos independentes para determinar se h√° diferen√ßas significativas.

    **Hip√≥teses:**
    - H‚ÇÄ (Hip√≥tese Nula): As distribui√ß√µes dos valores do par√¢metro s√£o iguais em todos os grupos (dias).
    - H‚ÇÅ (Hip√≥tese Alternativa): Pelo menos um grupo (dia) difere dos demais em sua distribui√ß√£o.

    **Signific√¢ncia (p-valor):**
    - **p < 0.05**: Rejeita H‚ÇÄ. H√° diferen√ßas estatisticamente significativas entre os grupos, indicando que a vermicompostagem influencia o par√¢metro.
    - **p ‚â• 0.05**: Aceita H‚ÇÄ. N√£o h√° evid√™ncias suficientes para afirmar diferen√ßas significativas, sugerindo que o par√¢metro √© est√°vel ou n√£o √© impactado de forma estatisticamente detect√°vel.
    """)

if __name__ == "__main__":
    main()
